# 把 AI 后台任务融入团队开发流程的实践指南

本指南结合本仓库的演示代码和你当前的开发模式，整理了引入「AI 后台任务」时需要补充的核心知识点与行动建议，帮助你在现有流程上逐步演进，而不是一次性重构。

## 1. 代码托管与访问控制

### 1.1 GitHub 以外的可行方案
- **GitHub Enterprise / GitHub AE**：部署在公司私有云或自建机房，功能与公开 GitHub 类似，能够运行 Actions、调用 GitHub Apps，也能配置 AI 后台任务。
- **GitLab + CI/CD + 自建 Runner**：GitLab 的 `CI_JOB_TOKEN`、`Project access tokens` 可以授权自动化脚本访问仓库；使用 GitLab Agent（在 Kubernetes 中运行）可实现“后台任务”拉取代码、提交 MR。
- **Gitea / Forgejo + Actions**：这些自托管平台已经兼容 GitHub Actions 风格的工作流，可以复用本仓库的 `scripts/ai-runner.js` 思路。
- **内部 Git + CI 平台**：即使没有现成的 Actions，也可以通过 Jenkins、GitLab Runner 或自研流水线在 CI 成功后触发脚本，调用 OpenAI / Azure OpenAI / 企业内 LLM 完成自动化任务。

> 关键点：后台任务的前提不是“必须放在公开 GitHub”，而是**拥有一个能被自动化系统安全访问的 Git 仓库**，并能在 CI / 任务执行器里调用脚本。

### 1.2 权限与安全
- 使用**最小权限令牌**（PAT、App Token、CI Job Token）让后台任务脚本只能访问指定仓库或分支。
- 将模型调用所需的 API Key 存放在 CI 的 Secrets 中，避免硬编码。
- 对后台任务产生的 PR 设置受控目录（例如本仓库的 AI 只写 `tests/**`），防止误改核心业务代码。

## 2. 梳理现有开发流程的“插入点”

你当前的流程大致为：
1. 业务沟通 → 形成前后端方案
2. 人工或 AI 辅助实现前端、后端
3. 纯人工功能测试
4. 领导打包上线

要融入后台任务，需要识别能够稳定复用的“触发节点”和“可自动化的输出”。结合本项目的示例，可以从以下环节入手：

### 2.1 代码实现阶段
- **前端页面生成**：让后台任务根据约定的 UI 模板自动补充样式、测试快照或 Storybook 示例。
- **后端约定检查**：利用后台任务执行静态规则（命名规范、DTO 结构等），生成问题清单或修复建议。

### 2.2 测试阶段
- 本仓库示范了在 PR 的 CI 成功后，由 `AI Tasks` 工作流读取 diff，生成 `tests/` 下的测试骨架。你可以：
  - 让后台任务根据 PHPDoc / OpenAPI / 用例描述，生成 Codeception / PHPUnit 用例骨架。
  - 输出测试检查表，提示人工测试需要覆盖的路径，减少遗漏。

### 2.3 发布阶段
- 在打包前触发后台任务执行“上线清单”，检查数据库迁移、配置变更、回滚方案是否齐备。
- 自动生成 Release Note 草稿，帮助领导审批。

## 3. 构建最小可行的后台任务闭环

按照“从易到难”分三步推进：

### 3.1 先在本地或内网模拟
- 克隆本仓库，阅读 `scripts/ai-runner.js`，理解如何在 CI 中读取 PR diff、生成文件、提交 PR。
- 在公司内网搭建一套 GitLab/Gitea，配置一个最简单的流水线：`php-cs-fixer` + `phpstan` + 单元测试，确认自动化环境稳定。

### 3.2 引入只读型任务
- 设计一个不会直接改代码的后台任务，例如生成测试计划 Markdown 或补充接口文档。
- 这样即便 AI 输出不理想，也不会破坏现有功能，团队能逐渐适应“让任务在后台跑”的节奏。

### 3.3 逐步放开写权限
- 在受控目录（`tests/`, `docs/`）内允许 AI 提交内容，建立 Code Review 规范：每次 AI PR 仍需人工合并，确保符合团队要求。
- 结合你们已有的后端框架规范，沉淀 Prompt 模板与规则文件，减少重复描述。

## 4. 与现有技能栈的衔接

- **PHP / Yii2 规范**：把项目已有的编码规范转成 `phpcs`, `php-cs-fixer`, `phpstan.neon` 等配置，让后台任务在生成或修改代码后自动运行这些工具，未通过则阻止提交。
- **AI 提示词模板**：整理常见场景（新增控制器、扩展 ActiveRecord、编写前端交互）的“输入-输出”范式，放在 `docs/prompts/*.md`，供后台任务复用。
- **人工测试经验沉淀**：每次人工测试后，把关键流程整理成用例描述，逐步转化为自动化测试，或成为 AI 生成测试脚本的训练素材。

## 5. 后续进阶方向

1. **CI/CD 基础**：学习 GitHub Actions / GitLab CI 的 `workflow` / `.gitlab-ci.yml` 语法，理解如何在构建阶段拉起 Node / PHP 环境执行脚本。
2. **队列与事件总线**：当需求增多时，可以把“后台任务”改成消息队列（RabbitMQ、Kafka），由 Worker 拉取任务执行，避免阻塞 CI。
3. **企业知识库对接**：把公司内部的规范文档、数据库字典等接入向量检索，让后台任务在生成代码或测试时参考真实上下文。
4. **安全审计**：引入 SAST/DAST 工具（例如 SonarQube、OWASP ZAP）作为后台任务的一部分，补足当前缺乏自动化测试的短板。

---

> 如果想快速体验，可以按照 README 的 Quick start 把仓库推到自己的 GitHub 账号，在个人项目里先跑通一次。理解了触发流程和产出形式后，再迁移到公司内网的 Git 服务上，实现同样的逻辑。

